
# <img src="images/ViTAR.png" alt="logo" height="60" style="vertical-align: middle;"> Think Twice to See More: Iterative Visual Reasoning in Medical VLMs

## ğŸ“– Overview  

We introduce **ViTAR**, a novel VLM framework that emulates the **iterative reasoning process of human experts** through a cognitive chain of *â€œthink â†’ act â†’ rethink â†’ answerâ€*. ViTAR treats medical images as **interactive cognitive objects**, enabling models to perform **multi-step visual reasoning**.  

Key contributions of ViTAR include:  
- ğŸ“‚ **Curated Instruction Data**:  
  - **1K interactive examples** encoding expert-like diagnostic behaviors.  
  - **16K VQA training samples** targeting fine-grained visual diagnosis.  
- ğŸ§  **Two-Stage Training Strategy**:  
  - **Supervised fine-tuning (SFT)** to guide cognitive reasoning trajectories.  
  - **Reinforcement learning (RL)** to optimize diagnostic decision-making.  
- ğŸ” **Mechanistic Insights**:  
  - Visual attention analysis shows that across the *â€œthinkâ€ â†’ â€œrethinkâ€* rounds, ViTAR increasingly anchors attention to **clinically critical regions**, sustaining high attention allocation to visual tokens during reasoning.  


 

---

## ğŸ§  Framework  
<div align="center">
  <img src="images/framework.jpg" width="90%" alt="Workflow">

 A framework of ViTAR.
  

</div>


